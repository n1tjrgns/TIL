# 하둡이란?

##### 하둡

- 분산 환경에서 빅 데이터를 저장하고 처리할 수 있는 자바 기반의 오픈 소스 프레임 워크.
- 하나의 성능 좋은 컴퓨터 대신, 범용 컴퓨터 여러대를 클러스트화 해서 큰 크기의 데이터를 병렬로 동시에 처리하여 처리 속도를 높이는 것을 목적



##### 구성요소

4개의 주요 모듈로 구성(핵심은 HDFS와 맵리듀스)

1. 하둡 분산형 파일시스템(Hadoop Distributed FileSystem, HDFS)

   - 하둡 네트워크에 연결된 기기에 데이터를 저장하는 분산형 파일시스템
- 여러개의 서버를 하나의 서버처럼 묶어서 데이터를 저장
  
2. 하둡 공통모듈(Hadoop Common)
   
   - 하둡의 다른 모듈을 지원하기 위한 공통 컴포넌트 모듈
3. 하둡 YARN
   
   - 병렬처리를 위한 클러스터 자원관리 및 스케줄링 담당
4. 하둡 맵리듀스(Mapreduce)
   - 분산되어 저장된 데이터를 병렬 처리할 수 있게 해주는 분산 처리 모듈

   

##### 장단점

-  장점
  - 오픈소스로 라이센스에 대한 비용 부담이 적음
  - 시스템을 중단하지 않고, 장비의 추가가 용이 (Scale Out)
  - 일부 장비에 장애가 발생하더라도 전체 시스템 사용에 영향이 적음 (Fault tolerance)
  - 저렴한 구축 비용과 비용대비 빠른 데이터 처리
  - 오프라인 배치 프로세싱에 최적화
- 단점
  - HDFS에 저장된 데이터 변경 불가 (2.0버전부터는 인터페이스 제공)
  - 실시간 데이터 분석 같이 신속하게 처리해야 하는 작업에는 부적함
  - 너무 많은 버전과 부실한  서포트
  - 설정의 어려움





##### 맵리듀스의 원리

100개의 자료를 1명이 100개 보는 것 보다 100명이 1개씩 보는 것이 빠른 것은 당연하다.

이것이 분산처리의 핵심이다. 하지만 100명이 본 결과를 취합하고 정리해야 하는 소요가 있고, 각 1개 마다 분량이 서로 다르다면 이를 동일한 크기로 나누는 일이 쉽지가 않다.



맵리듀스는 이러한 처리를 돕는 역할을 한다. 

이름 그대로 Map 단계와 Reduce 단계로 이루어진다.



Map 단계에서는 흩어져 있는 데이터를 Key, Value로 데이터를 묶어준다.

예를 들어 key는 몇 번째 데이터인지, value는 값을 추출한 정보를 가진다. 그리고 Reduce 단계는 Map 단계의 key를 중심으로 필터링 및 정렬한다.

하둡에서는 이 Map과 Reduce를 함수를 통해 구현하고 맵리듀스 Job을 통해 제어한다.











참고

<<https://wikidocs.net/22654>>